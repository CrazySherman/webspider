# webspider
The project is dedicated to analyze NBA lineup data and provide a regression model that can predict team's lineup scores. However, given the only the web stats available on NBA.com, we need a dedicated crawl to scrape the nba database and form our dataset. The sample folder contains a Scrapy project including multiple spider classes, one of them is used to scrape NBA player stats. As for the regression model, since it's obviously non-linear, and we dont wanna mess with non-linear SVM kernels. Surpirsingly after training CNN for a few months, I guess NN might be a good method to train non-linear regression models, so here to construct a simple neural network from brick & cement, and see how it goes with NBA lineup data.
## Data scraper
The sample folder is organized as standard Scrapy structure, `webspider/sample/sample/spiders/PlayerSpider.py` is the spider to extract player stats. We have included the following metrics of a player: "FGM, FGA, 3PM, 3PA, FTM, REB, AST, TOV, STL, BLK, +/-" together 11 metrics. The spider initates a 2 level crawling: first went to player.nba.com to extract player index number, then following the index number url link to the player profile page to scrape the stat table. One difficulty we need to overstep is javascript rendering, both player index number and stats(metrics) are js-rendered, and scrapy itself doesn't have a js rendering library, so we started another Splash server on another host and send POST request to the Splash server to rendered the given url. 3 parameters govern the performance of the spider: the number of request u pass to the crawling pipeline, time interval between each request, and the `wait` argumenting passed to Splash renderer. The parameter values are listed in the first block of the file, bad parameters could result in constant render failure, and there is also limited processing load on Splash server. It turns out that NBA.com is purposely cutting down spider rendering traffics. During my experiment, Nba.com apparently refused frequent rendering request from the same server. As a result it took me almost a day to download all the player data, almost as painful as click-and-write myself. The player stats table is written in players.jl file as json objects.
Lineup data consist of two fields: 5 players on the court, which forms the "lineup", and the +/- score. We already have 11 metrics for each player, so there are total 55 length feature vector for a lineup sample, and +/- score is used as regression label. There are myriads of lineup data in the official database, however I cannot execute the page-turning js code on the stats page, even with Splash's js-source argument. Writing Chrome add-on could possibly solve this, but i seriously dont have the time and mood. So i just manually downloaded the 2015/16 playoffs lineup data, and use xpath to extract lineup data into the `webspider/mystats.txt` file.  
## Simple Neuraul Network training
